{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from collections import Counter\n",
    "\n",
    "# Wikilabels\n",
    "df = pd.read_csv('../data/wiki/wiki_name_race.csv')\n",
    "\n",
    "# drop rows with NAN forename or surname\n",
    "df.dropna(subset=['name_first', 'name_last'], inplace=True)\n",
    "\n",
    "# replace NAN middle name with empty string\n",
    "df.name_middle = df.name_middle.fillna('')\n",
    "\n",
    "sdf = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# remove chars not unicode alphabets, dash or space\\nremove_special_chars = lambda x: ''.join([c if c.isalpha() or c == '-' or c == ' ' else '?' for c in x])\\nsdf['name_last'] = sdf['name_last'].apply(remove_special_chars)\\nsdf['name_first'] = sdf['name_first'].apply(remove_special_chars)\\nsdf['name_middle'] = sdf['name_middle'].apply(remove_special_chars)\\n\\nprint('surname char counts:')\\nprint(Counter(sdf['name_last'].str.cat()))\\nprint('\\n')\\nprint('forename char counts:')\\nprint(Counter(sdf['name_first'].str.cat()))\\nprint('\\n')\\nprint('midname char counts:')\\nprint(Counter(sdf['name_middle'].str.cat()))\\nprint('\\n')\\n\\n# drop rows with bad chars\\nsdf = sdf[~sdf.name_last.str.contains('[?]')]\\nsdf = sdf[~sdf.name_first.str.contains('[?]')]\\nsdf = sdf[~sdf.name_middle.str.contains('[?]')]\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# remove chars not unicode alphabets, dash or space\n",
    "remove_special_chars = lambda x: ''.join([c if c.isalpha() or c == '-' or c == ' ' else '?' for c in x])\n",
    "sdf['name_last'] = sdf['name_last'].apply(remove_special_chars)\n",
    "sdf['name_first'] = sdf['name_first'].apply(remove_special_chars)\n",
    "sdf['name_middle'] = sdf['name_middle'].apply(remove_special_chars)\n",
    "\n",
    "print('surname char counts:')\n",
    "print(Counter(sdf['name_last'].str.cat()))\n",
    "print('\\n')\n",
    "print('forename char counts:')\n",
    "print(Counter(sdf['name_first'].str.cat()))\n",
    "print('\\n')\n",
    "print('midname char counts:')\n",
    "print(Counter(sdf['name_middle'].str.cat()))\n",
    "print('\\n')\n",
    "\n",
    "# drop rows with bad chars\n",
    "sdf = sdf[~sdf.name_last.str.contains('[?]')]\n",
    "sdf = sdf[~sdf.name_first.str.contains('[?]')]\n",
    "sdf = sdf[~sdf.name_middle.str.contains('[?]')]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count distribution of ethnicity by surname, forename and middle name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       name_last\n",
      "race                                            \n",
      "Asian,GreaterEastAsian,EastAsian            2739\n",
      "Asian,GreaterEastAsian,Japanese             4107\n",
      "Asian,IndianSubContinent                    3802\n",
      "GreaterAfrican,Africans                     3149\n",
      "GreaterAfrican,Muslim                       4537\n",
      "GreaterEuropean,British                    15943\n",
      "GreaterEuropean,EastEuropean                6576\n",
      "GreaterEuropean,Jewish                      6285\n",
      "GreaterEuropean,WestEuropean,French         9503\n",
      "GreaterEuropean,WestEuropean,Germanic       3313\n",
      "GreaterEuropean,WestEuropean,Hispanic       6229\n",
      "GreaterEuropean,WestEuropean,Italian        8630\n",
      "GreaterEuropean,WestEuropean,Nordic         3168\n",
      "77981\n",
      "                                       name_first\n",
      "race                                             \n",
      "Asian,GreaterEastAsian,EastAsian             1813\n",
      "Asian,GreaterEastAsian,Japanese              3265\n",
      "Asian,IndianSubContinent                     4191\n",
      "GreaterAfrican,Africans                      2380\n",
      "GreaterAfrican,Muslim                        3026\n",
      "GreaterEuropean,British                      5326\n",
      "GreaterEuropean,EastEuropean                 2115\n",
      "GreaterEuropean,Jewish                       2866\n",
      "GreaterEuropean,WestEuropean,French          2477\n",
      "GreaterEuropean,WestEuropean,Germanic        1281\n",
      "GreaterEuropean,WestEuropean,Hispanic        2888\n",
      "GreaterEuropean,WestEuropean,Italian         2872\n",
      "GreaterEuropean,WestEuropean,Nordic          1394\n",
      "35894\n",
      "                                       name_middle\n",
      "race                                              \n",
      "Asian,GreaterEastAsian,EastAsian               540\n",
      "Asian,GreaterEastAsian,Japanese                258\n",
      "Asian,IndianSubContinent                      1053\n",
      "GreaterAfrican,Africans                        433\n",
      "GreaterAfrican,Muslim                          986\n",
      "GreaterEuropean,British                       2338\n",
      "GreaterEuropean,EastEuropean                   472\n",
      "GreaterEuropean,Jewish                         593\n",
      "GreaterEuropean,WestEuropean,French           1015\n",
      "GreaterEuropean,WestEuropean,Germanic          332\n",
      "GreaterEuropean,WestEuropean,Hispanic         1505\n",
      "GreaterEuropean,WestEuropean,Italian           809\n",
      "GreaterEuropean,WestEuropean,Nordic            655\n",
      "10989\n",
      "\n",
      "total rows = 133872, total classes = 13\n"
     ]
    }
   ],
   "source": [
    "# count surname freq\n",
    "surname_counts = sdf.groupby('race').agg({'name_last': 'nunique'})\n",
    "print(surname_counts)\n",
    "print(surname_counts.name_last.sum())\n",
    "\n",
    "# count forename freq\n",
    "forename_counts = sdf.groupby('race').agg({'name_first': 'nunique'})\n",
    "print(forename_counts)\n",
    "print(forename_counts.name_first.sum())\n",
    "\n",
    "# count middle name freq\n",
    "midname_counts = sdf.groupby('race').agg({'name_middle': 'nunique'})\n",
    "print(midname_counts)\n",
    "print(midname_counts.name_middle.sum())\n",
    "\n",
    "total_rows = sdf.shape[0]\n",
    "total_classes = surname_counts.shape[0]\n",
    "print('\\ntotal rows = %d, total classes = %d' % (total_rows, total_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize surname, forename and middle name into n-grams and apply TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat last name, first name and middle name\n",
    "sdf['name'] = '_' + sdf['name_last'] + '_' + sdf['name_first'] + '_' + sdf['name_middle'] + '_'\n",
    "\n",
    "# build n-grams\n",
    "min_ngrams = 2\n",
    "max_ngrams = 4\n",
    "#vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=3, ngram_range=(min_ngrams, max_ngrams), lowercase=True)\n",
    "vect = TfidfVectorizer(analyzer='char', ngram_range=(min_ngrams, max_ngrams), lowercase=True)\n",
    "X = vect.fit_transform(sdf.name)\n",
    "y = np.array(sdf.race.astype('category').cat.codes)\n",
    "\n",
    "# spit training and test datasets\n",
    "print('total features = %d' % X.shape[0])\n",
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "\n",
    "X_train_resampled = X_train\n",
    "y_train_resampled = y_train\n",
    "\n",
    "#X_train_sampled, y_train_resampled = RandomOverSampler(random_state=0).fit_sample(X_train, y_train)\n",
    "#X_train_sampled, y_train_resampled = SMOTE().fit_sample(X_train, y_train)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "print(sorted(Counter(y_train).items()))\n",
    "print(sorted(Counter(y_train_resampled).items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "print('Train...')\n",
    "#model = XGBClassifier(max_depth=9, objective='multi:softmax', num_classes_total_classes)\n",
    "model = LogisticRegression(max_iter=300, solver='sag', class_weight=None, n_jobs=3)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print('Predict...')\n",
    "y_pred = model.predict(X_test)\n",
    "score = model.score(X_test, y_test)\n",
    "print('Test score = %f' % score)\n",
    "\n",
    "target_names = list(sdf.race.astype('category').cat.categories)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = ['_abe_shinzo__', '_xi_jinping__', '_netanyahu_benjamin__', '_putin_vladimir__',\n",
    "              '_obama_barrack__', '_modi_narendra__', '_conte_giuseppe__', '_johnson_boris__']\n",
    "\n",
    "X_query = vect.transform(test_names).toarray()\n",
    "y_query = model.predict(X_query)\n",
    "\n",
    "print(y_query)\n",
    "print([target_names[i] for i in y_query])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "tfidf_filename = '../models/wiki/logistic_regression/tfidf.pkl'\n",
    "model_filename = '../models/wiki/logistic_regression/wiki_name_logreg.joblib'\n",
    "\n",
    "dump(model, model_filename)\n",
    "pickle.dump(vect, open(tfidf_filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "loaded_model = load(model_filename)\n",
    "\n",
    "# load vectorizer\n",
    "tf1 = pickle.load(open(tfidf_filename, 'rb'))\n",
    "loaded_vect = TfidfVectorizer(vocabulary=tf1.vocabulary_, analyzer='char', ngram_range=(min_ngrams, max_ngrams), lowercase=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
